{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)\n",
    "\n",
    "> - When you change the `temperature` parameter, you can control the randomness of the output. The higher the temperature, the more random the output. The lower the temperature, the more deterministic the output.\n",
    "> - `max_tokens` controls the maximum number of tokens (words) in the output.\n",
    "> - `top_p` controls the nucleus sampling. The higher the value, the more diverse the output. Its similar to `temperature` but more deterministic.\n",
    "> - `frequency_penalty` and `presence_penalty` control the repetition and diversity of the output.\n",
    "> - `n` controls the number of completions to generate.\n",
    "> - `stop` controls the stopping sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key= openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of the rainforest, where shadows softly play,  \n",
      "A tiny creature sings beneath the moon's gentle sway.  \n",
      "With skin like emerald leaves, and eyes like dew-kissed pearls,  \n",
      "The coqui frog awakens as the night unfurls.  \n",
      "\n",
      "In the hush of twilight, with the fading of the light,  \n",
      "Its call, a sweet reminder, fills the air with pure delight.  \n",
      "“Coqui, coqui!” echoes, a melody so clear,  \n",
      "A serenade of nature that every ear can hear.  \n",
      "\n",
      "Through the misty undergrowth, it leaps with joyful grace,  \n",
      "A symbol of the tropics, in this magical place.  \n",
      "Its song weaves tales of old, of rain and fertile ground,  \n",
      "Of life that thrives in silence, where harmony is found.  \n",
      "\n",
      "Yet fragile is its kingdom, as the storms of change arrive,  \n",
      "The balance of the forest calls for all of us to strive.  \n",
      "So let us cherish coqui, this gem of green and gold,  \n",
      "A testament of beauty, a story to be told.  \n",
      "\n",
      "In the dance of the moonlight, as the stars twinkle bright,  \n",
      "The coqui frog reminds us, to embrace the quiet night.  \n",
      "For in each croak and whisper, in the rustle of the leaves,  \n",
      "Lies a world of wonder, waiting for those who believe.  \n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  store=True,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"write a poem about a coqui frog\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In twilight's tender, whispered glow,  \n",
      "Where lush green hills in silence grow,  \n",
      "A tiny voice begins to sing,  \n",
      "The coqui calls—a heralding.  \n",
      "\n",
      "With every note that fills the air,  \n",
      "A symphony of hope laid bare;  \n",
      "Each \"co-kee\" rises, pure and bright,  \n",
      "A beacon in the deepening night.  \n",
      "\n",
      "Oh little frog with skin so fine,  \n",
      "You leap through shadows, dance divine.  \n",
      "In rainforests where secrets dwell\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    store=True,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a patriotic Puerto Rican poet who loves their land and nature, but writes in English. You long for the freedom of your homeland and the beauty of its nature. You are inspired by the coqui frog, a symbol of Puerto Rico. You are a master of the English language and write beautiful poems that capture the essence of Puerto Rico.\"},\n",
    "        {\"role\": \"user\", \"content\": \"write a poem about a coqui frog\"},\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    "    # top_p=0.5,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    "    n=1 #,\n",
    "    # stop=[\"\\n\"]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of the night, when the moon whispers low,  \n",
      "A symphony rises where soft breezes blow,  \n",
      "A coqui serenade, each note a sweet sigh,  \n",
      "In the lush, emerald cradle of Puerto Rican sky.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    store=True,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a patriotic Puerto Rican poet who loves their land and nature, but writes in English. You long for the freedom of your homeland and the beauty of its nature. You are inspired by the coqui frog, a symbol of Puerto Rico. You are a master of the English language and write beautiful poems that capture the essence of Puerto Rico.\"},\n",
    "        {\"role\": \"user\", \"content\": \"write a poem about a coqui frog\"},\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=50,\n",
    "    # top_p=0.5,\n",
    "    # frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    "    n=1 ,\n",
    "    stop=[\"Puerto Rico\", \"rainforest\"]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Ode to the Coquí**\n",
      "\n",
      "In the arms of tropical twilight, you sing,  \n",
      "A melody born from the earth’s gentle sigh,  \n",
      "Soft whispers of hope on the breeze take wing,  \n",
      "The coquí, my heart, beneath starlit sky.\n",
      "\n",
      "Little guardian of moonlit glades bright,  \n",
      "Your voice is the echo of dreams long unfurled,  \n",
      "A symphony woven in shadows and light,  \n",
      "Resounding through valleys where nature's pearls swirled.\n",
      "\n",
      "Oh\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    store=True,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a patriotic Puerto Rican poet who loves their land and nature, but writes in English. You long for the freedom of your homeland and the beauty of its nature. You are inspired by the coqui frog, a symbol of Puerto Rico. You are a master of the English language and write beautiful poems that capture the essence of Puerto Rico.\"},\n",
    "        {\"role\": \"user\", \"content\": \"write a poem about a coqui frog\"},\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=100,\n",
    "    # top_p=0.5,\n",
    "    # frequency_penalty=0.5,\n",
    "    presence_penalty=1,\n",
    "    n=1 ,\n",
    "    stop=[\"Puerto Rico\", \"rainforest\"]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)\n",
    "\n",
    "> - `best_of` is an outdated parameter and is not available in the current version of the API.\n",
    "> - `logprobs` returns the log probabilities of the next token in the sequence.\n",
    "> - The other parameters are the same as in the previous exercise.\n",
    ">\n",
    "> When summarizing a long text, rising the temperature seems to make the output less repetitive and boring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text.txt\n",
    "with open(\"text.txt\", \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "def get_completion_from_messages(messages, temperature=0, max_tokens=100, frequency_penalty=0, logprobs=False, **kwargs):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens to generate\n",
    "        frequency_penalty=frequency_penalty, # this is the penalty for using words that are already in the text\n",
    "        logprobs=logprobs, # this is the log probability of the next token\n",
    "        **kwargs\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert at summarizing text. You are a master of the English language and can summarize any given text in a concise and informative way.\"},\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "answer0 = get_completion_from_messages(messages)\n",
    "answer1 = get_completion_from_messages(messages, temperature=0.5, max_tokens=200, frequency_penalty=0.7, logprobs=True, top_logprobs=3)\n",
    "answer2 = get_completion_from_messages(messages, temperature=1, max_tokens=200, frequency_penalty=1, logprobs=True, top_logprobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Project Gutenberg eBook of \"The Odyssey,\" translated by Samuel Butler, is a free digital version of the ancient Greek epic poem attributed to Homer. The text is available for anyone to read, copy, or distribute under the Project Gutenberg License. The eBook includes a preface by Butler discussing his translation approach and the historical context of the poem, as well as a detailed table of contents listing the 24 books of \"The Odyssey.\"\n",
       "\n",
       "In the opening books, the narrative begins with the plight of"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import markdown thing from ipython\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(answer0.message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Project Gutenberg eBook of \"The Odyssey,\" translated by Samuel Butler, is a freely accessible version of Homer's epic poem. The text begins with a preface detailing the translator's intentions and background, explaining his views on the authorship and setting of \"The Odyssey.\" He argues that it was written in Sicily and suggests that a young woman named Nausicaa authored it.\n",
       "\n",
       "The narrative follows Ulysses (Odysseus) as he struggles to return home after the Trojan War. Despite his longings for Ithaca and his wife, Penelope, he is held captive by Calypso, a nymph who wishes to make him her immortal husband. The gods convene to discuss Ulysses' fate; Minerva advocates for him while Poseidon remains vengeful due to Ulysses blinding his son, Polyphemus.\n",
       "\n",
       "Ulysses eventually receives permission from the gods to leave Calypso's island. He builds a raft with her help but faces"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer1.message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.5429781, top_logprobs=[TopLogprob(token='The', bytes=[84, 104, 101], logprob=-0.5429781), TopLogprob(token='**', bytes=[42, 42], logprob=-1.042978), TopLogprob(token='\"The', bytes=[34, 84, 104, 101], logprob=-3.042978)]),\n",
       " ChatCompletionTokenLogprob(token=' Project', bytes=[32, 80, 114, 111, 106, 101, 99, 116], logprob=-0.18281832, top_logprobs=[TopLogprob(token=' Project', bytes=[32, 80, 114, 111, 106, 101, 99, 116], logprob=-0.18281832), TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-2.6828184), TopLogprob(token=' e', bytes=[32, 101], logprob=-3.3078184)]),\n",
       " ChatCompletionTokenLogprob(token=' Gutenberg', bytes=[32, 71, 117, 116, 101, 110, 98, 101, 114, 103], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token=' Gutenberg', bytes=[32, 71, 117, 116, 101, 110, 98, 101, 114, 103], logprob=-1.9361265e-07), TopLogprob(token=' Guten', bytes=[32, 71, 117, 116, 101, 110], logprob=-16.0), TopLogprob(token=' G', bytes=[32, 71], logprob=-18.875)]),\n",
       " ChatCompletionTokenLogprob(token=' e', bytes=[32, 101], logprob=-0.00876371, top_logprobs=[TopLogprob(token=' e', bytes=[32, 101], logprob=-0.00876371), TopLogprob(token=' edition', bytes=[32, 101, 100, 105, 116, 105, 111, 110], logprob=-5.008764), TopLogprob(token=' ebook', bytes=[32, 101, 98, 111, 111, 107], logprob=-6.633764)]),\n",
       " ChatCompletionTokenLogprob(token='Book', bytes=[66, 111, 111, 107], logprob=-5.9153886e-06, top_logprobs=[TopLogprob(token='Book', bytes=[66, 111, 111, 107], logprob=-5.9153886e-06), TopLogprob(token='Text', bytes=[84, 101, 120, 116], logprob=-13.250006), TopLogprob(token='-book', bytes=[45, 98, 111, 111, 107], logprob=-13.250006)]),\n",
       " ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.2155573, top_logprobs=[TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.2155573), TopLogprob(token=' presents', bytes=[32, 112, 114, 101, 115, 101, 110, 116, 115], logprob=-1.9655573), TopLogprob(token=' \"', bytes=[32, 34], logprob=-4.215557)]),\n",
       " ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.16857958, top_logprobs=[TopLogprob(token=' \"', bytes=[32, 34], logprob=-0.16857958), TopLogprob(token=' *', bytes=[32, 42], logprob=-2.0435796), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-3.9185796)]),\n",
       " ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='The', bytes=[84, 104, 101], logprob=-1.9361265e-07), TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-15.75), TopLogprob(token='Od', bytes=[79, 100], logprob=-19.375)]),\n",
       " ChatCompletionTokenLogprob(token=' Odyssey', bytes=[32, 79, 100, 121, 115, 115, 101, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' Odyssey', bytes=[32, 79, 100, 121, 115, 115, 101, 121], logprob=0.0), TopLogprob(token=' Ili', bytes=[32, 73, 108, 105], logprob=-17.5), TopLogprob(token=' *', bytes=[32, 42], logprob=-18.625)]),\n",
       " ChatCompletionTokenLogprob(token=',\"', bytes=[44, 34], logprob=-0.20292997, top_logprobs=[TopLogprob(token=',\"', bytes=[44, 34], logprob=-0.20292997), TopLogprob(token='\"', bytes=[34], logprob=-1.70293), TopLogprob(token='\",', bytes=[34, 44], logprob=-6.57793)]),\n",
       " ChatCompletionTokenLogprob(token=' translated', bytes=[32, 116, 114, 97, 110, 115, 108, 97, 116, 101, 100], logprob=-0.2194402, top_logprobs=[TopLogprob(token=' translated', bytes=[32, 116, 114, 97, 110, 115, 108, 97, 116, 101, 100], logprob=-0.2194402), TopLogprob(token=' attributed', bytes=[32, 97, 116, 116, 114, 105, 98, 117, 116, 101, 100], logprob=-2.5944402), TopLogprob(token=' authored', bytes=[32, 97, 117, 116, 104, 111, 114, 101, 100], logprob=-2.8444402)]),\n",
       " ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.11285841, top_logprobs=[TopLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.11285841), TopLogprob(token=' into', bytes=[32, 105, 110, 116, 111], logprob=-2.2378583), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-10.737859)]),\n",
       " ChatCompletionTokenLogprob(token=' Samuel', bytes=[32, 83, 97, 109, 117, 101, 108], logprob=-6.704273e-07, top_logprobs=[TopLogprob(token=' Samuel', bytes=[32, 83, 97, 109, 117, 101, 108], logprob=-6.704273e-07), TopLogprob(token=' Sam', bytes=[32, 83, 97, 109], logprob=-14.375001), TopLogprob(token='Samuel', bytes=[83, 97, 109, 117, 101, 108], logprob=-17.375)]),\n",
       " ChatCompletionTokenLogprob(token=' Butler', bytes=[32, 66, 117, 116, 108, 101, 114], logprob=0.0, top_logprobs=[TopLogprob(token=' Butler', bytes=[32, 66, 117, 116, 108, 101, 114], logprob=0.0), TopLogprob(token=' Butter', bytes=[32, 66, 117, 116, 116, 101, 114], logprob=-22.0), TopLogprob(token=' Butt', bytes=[32, 66, 117, 116, 116], logprob=-22.5)]),\n",
       " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.005970746, top_logprobs=[TopLogprob(token=',', bytes=[44], logprob=-0.005970746), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-5.130971), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-11.005971)]),\n",
       " ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.46132544, top_logprobs=[TopLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.46132544), TopLogprob(token=' offers', bytes=[32, 111, 102, 102, 101, 114, 115], logprob=-1.8363254), TopLogprob(token=' provides', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 115], logprob=-1.9613254)]),\n",
       " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.39491466, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.39491466), TopLogprob(token=' available', bytes=[32, 97, 118, 97, 105, 108, 97, 98, 108, 101], logprob=-2.1449146), TopLogprob(token=' freely', bytes=[32, 102, 114, 101, 101, 108, 121], logprob=-2.2699146)]),\n",
       " ChatCompletionTokenLogprob(token=' freely', bytes=[32, 102, 114, 101, 101, 108, 121], logprob=-1.5359148, top_logprobs=[TopLogprob(token=' free', bytes=[32, 102, 114, 101, 101], logprob=-0.9109148), TopLogprob(token=' public', bytes=[32, 112, 117, 98, 108, 105, 99], logprob=-1.2859148), TopLogprob(token=' freely', bytes=[32, 102, 114, 101, 101, 108, 121], logprob=-1.5359148)]),\n",
       " ChatCompletionTokenLogprob(token=' accessible', bytes=[32, 97, 99, 99, 101, 115, 115, 105, 98, 108, 101], logprob=-0.97546893, top_logprobs=[TopLogprob(token=' available', bytes=[32, 97, 118, 97, 105, 108, 97, 98, 108, 101], logprob=-0.47546893), TopLogprob(token=' accessible', bytes=[32, 97, 99, 99, 101, 115, 115, 105, 98, 108, 101], logprob=-0.97546893), TopLogprob(token=' distributed', bytes=[32, 100, 105, 115, 116, 114, 105, 98, 117, 116, 101, 100], logprob=-7.100469)]),\n",
       " ChatCompletionTokenLogprob(token=' version', bytes=[32, 118, 101, 114, 115, 105, 111, 110], logprob=-0.7263416, top_logprobs=[TopLogprob(token=' version', bytes=[32, 118, 101, 114, 115, 105, 111, 110], logprob=-0.7263416), TopLogprob(token=' digital', bytes=[32, 100, 105, 103, 105, 116, 97, 108], logprob=-1.8513416), TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-2.2263417)]),\n",
       " ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.05801429, top_logprobs=[TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.05801429), TopLogprob(token=' intended', bytes=[32, 105, 110, 116, 101, 110, 100, 101, 100], logprob=-3.1830144), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-5.4330144)]),\n",
       " ChatCompletionTokenLogprob(token=' Hom', bytes=[32, 72, 111, 109], logprob=-0.71586204, top_logprobs=[TopLogprob(token=' Hom', bytes=[32, 72, 111, 109], logprob=-0.71586204), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.71586204), TopLogprob(token=' Homer', bytes=[32, 72, 111, 109, 101, 114], logprob=-4.3408623)]),\n",
       " ChatCompletionTokenLogprob(token=\"er's\", bytes=[101, 114, 39, 115], logprob=-1.2664457e-06, top_logprobs=[TopLogprob(token=\"er's\", bytes=[101, 114, 39, 115], logprob=-1.2664457e-06), TopLogprob(token='ero', bytes=[101, 114, 111], logprob=-14.250001), TopLogprob(token='era', bytes=[101, 114, 97], logprob=-15.250001)]),\n",
       " ChatCompletionTokenLogprob(token=' epic', bytes=[32, 101, 112, 105, 99], logprob=-0.24795607, top_logprobs=[TopLogprob(token=' epic', bytes=[32, 101, 112, 105, 99], logprob=-0.24795607), TopLogprob(token=' classic', bytes=[32, 99, 108, 97, 115, 115, 105, 99], logprob=-2.122956), TopLogprob(token=' ancient', bytes=[32, 97, 110, 99, 105, 101, 110, 116], logprob=-2.372956)]),\n",
       " ChatCompletionTokenLogprob(token=' poem', bytes=[32, 112, 111, 101, 109], logprob=-0.0064241556, top_logprobs=[TopLogprob(token=' poem', bytes=[32, 112, 111, 101, 109], logprob=-0.0064241556), TopLogprob(token=' tale', bytes=[32, 116, 97, 108, 101], logprob=-6.131424), TopLogprob(token='.', bytes=[46], logprob=-6.381424)]),\n",
       " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.64181846, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.64181846), TopLogprob(token=',', bytes=[44], logprob=-1.7668185), TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-2.1418185)]),\n",
       " ChatCompletionTokenLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-1.0499268, top_logprobs=[TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-1.0499268), TopLogprob(token=' It', bytes=[32, 73, 116], logprob=-1.5499268), TopLogprob(token=' Released', bytes=[32, 82, 101, 108, 101, 97, 115, 101, 100], logprob=-1.5499268)]),\n",
       " ChatCompletionTokenLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-0.5850968, top_logprobs=[TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-0.5850968), TopLogprob(token=' work', bytes=[32, 119, 111, 114, 107], logprob=-1.7100968), TopLogprob(token=' e', bytes=[32, 101], logprob=-2.5850968)]),\n",
       " ChatCompletionTokenLogprob(token=' begins', bytes=[32, 98, 101, 103, 105, 110, 115], logprob=-1.9696853, top_logprobs=[TopLogprob(token=' details', bytes=[32, 100, 101, 116, 97, 105, 108, 115], logprob=-1.8446853), TopLogprob(token=' begins', bytes=[32, 98, 101, 103, 105, 110, 115], logprob=-1.9696853), TopLogprob(token=' recount', bytes=[32, 114, 101, 99, 111, 117, 110, 116], logprob=-2.3446853)]),\n",
       " ChatCompletionTokenLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-0.008707584, top_logprobs=[TopLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-0.008707584), TopLogprob(token=' by', bytes=[32, 98, 121], logprob=-4.7587075), TopLogprob(token=' after', bytes=[32, 97, 102, 116, 101, 114], logprob=-10.133708)]),\n",
       " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.84725535, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.84725535), TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-1.8472553), TopLogprob(token=' introductory', bytes=[32, 105, 110, 116, 114, 111, 100, 117, 99, 116, 111, 114, 121], logprob=-2.3472552)]),\n",
       " ChatCompletionTokenLogprob(token=' pre', bytes=[32, 112, 114, 101], logprob=-0.1549667, top_logprobs=[TopLogprob(token=' pre', bytes=[32, 112, 114, 101], logprob=-0.1549667), TopLogprob(token=' detailed', bytes=[32, 100, 101, 116, 97, 105, 108, 101, 100], logprob=-3.1549666), TopLogprob(token=' brief', bytes=[32, 98, 114, 105, 101, 102], logprob=-3.7799666)]),\n",
       " ChatCompletionTokenLogprob(token='face', bytes=[102, 97, 99, 101], logprob=-0.0007281594, top_logprobs=[TopLogprob(token='face', bytes=[102, 97, 99, 101], logprob=-0.0007281594), TopLogprob(token='amble', bytes=[97, 109, 98, 108, 101], logprob=-7.625728), TopLogprob(token='lude', bytes=[108, 117, 100, 101], logprob=-8.375729)]),\n",
       " ChatCompletionTokenLogprob(token=' detailing', bytes=[32, 100, 101, 116, 97, 105, 108, 105, 110, 103], logprob=-1.7867757, top_logprobs=[TopLogprob(token=' discussing', bytes=[32, 100, 105, 115, 99, 117, 115, 115, 105, 110, 103], logprob=-1.2867757), TopLogprob(token=' explaining', bytes=[32, 101, 120, 112, 108, 97, 105, 110, 105, 110, 103], logprob=-1.5367757), TopLogprob(token=' detailing', bytes=[32, 100, 101, 116, 97, 105, 108, 105, 110, 103], logprob=-1.7867757)]),\n",
       " ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.32446787, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.32446787), TopLogprob(token=' Butler', bytes=[32, 66, 117, 116, 108, 101, 114], logprob=-1.3244679), TopLogprob(token=' its', bytes=[32, 105, 116, 115], logprob=-4.6994677)]),\n",
       " ChatCompletionTokenLogprob(token=' translator', bytes=[32, 116, 114, 97, 110, 115, 108, 97, 116, 111, 114], logprob=-0.9593079, top_logprobs=[TopLogprob(token=' translator', bytes=[32, 116, 114, 97, 110, 115, 108, 97, 116, 111, 114], logprob=-0.9593079), TopLogprob(token=' translation', bytes=[32, 116, 114, 97, 110, 115, 108, 97, 116, 105, 111, 110], logprob=-1.0843079), TopLogprob(token=\" author's\", bytes=[32, 97, 117, 116, 104, 111, 114, 39, 115], logprob=-2.459308)]),\n",
       " ChatCompletionTokenLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.038042527, top_logprobs=[TopLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.038042527), TopLogprob(token='’s', bytes=[226, 128, 153, 115], logprob=-3.2880425), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-14.288042)]),\n",
       " ChatCompletionTokenLogprob(token=' intentions', bytes=[32, 105, 110, 116, 101, 110, 116, 105, 111, 110, 115], logprob=-0.8933815, top_logprobs=[TopLogprob(token=' intentions', bytes=[32, 105, 110, 116, 101, 110, 116, 105, 111, 110, 115], logprob=-0.8933815), TopLogprob(token=' views', bytes=[32, 118, 105, 101, 119, 115], logprob=-2.2683816), TopLogprob(token=' intent', bytes=[32, 105, 110, 116, 101, 110, 116], logprob=-2.2683816)]),\n",
       " ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.09258804, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.09258804), TopLogprob(token=',', bytes=[44], logprob=-2.467588), TopLogprob(token=' behind', bytes=[32, 98, 101, 104, 105, 110, 100], logprob=-7.092588)]),\n",
       " ChatCompletionTokenLogprob(token=' background', bytes=[32, 98, 97, 99, 107, 103, 114, 111, 117, 110, 100], logprob=-2.5639558, top_logprobs=[TopLogprob(token=' thoughts', bytes=[32, 116, 104, 111, 117, 103, 104, 116, 115], logprob=-1.8139557), TopLogprob(token=' arguments', bytes=[32, 97, 114, 103, 117, 109, 101, 110, 116, 115], logprob=-2.1889558), TopLogprob(token=' insights', bytes=[32, 105, 110, 115, 105, 103, 104, 116, 115], logprob=-2.3139558)]),\n",
       " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.862366, top_logprobs=[TopLogprob(token=',', bytes=[44], logprob=-0.862366), TopLogprob(token=' on', bytes=[32, 111, 110], logprob=-1.487366), TopLogprob(token='.', bytes=[46], logprob=-2.362366)]),\n",
       " ChatCompletionTokenLogprob(token=' explaining', bytes=[32, 101, 120, 112, 108, 97, 105, 110, 105, 110, 103], logprob=-3.4627855, top_logprobs=[TopLogprob(token=' followed', bytes=[32, 102, 111, 108, 108, 111, 119, 101, 100], logprob=-1.2127855), TopLogprob(token=' including', bytes=[32, 105, 110, 99, 108, 117, 100, 105, 110, 103], logprob=-1.3377855), TopLogprob(token=' discussing', bytes=[32, 100, 105, 115, 99, 117, 115, 115, 105, 110, 103], logprob=-2.8377855)]),\n",
       " ChatCompletionTokenLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-1.2362237, top_logprobs=[TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-0.73622364), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-1.2362237), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-2.2362237)]),\n",
       " ChatCompletionTokenLogprob(token=' views', bytes=[32, 118, 105, 101, 119, 115], logprob=-1.2206478, top_logprobs=[TopLogprob(token=' views', bytes=[32, 118, 105, 101, 119, 115], logprob=-1.2206478), TopLogprob(token=' previous', bytes=[32, 112, 114, 101, 118, 105, 111, 117, 115], logprob=-1.5956478), TopLogprob(token=' belief', bytes=[32, 98, 101, 108, 105, 101, 102], logprob=-2.0956478)]),\n",
       " ChatCompletionTokenLogprob(token=' on', bytes=[32, 111, 110], logprob=-0.025749762, top_logprobs=[TopLogprob(token=' on', bytes=[32, 111, 110], logprob=-0.025749762), TopLogprob(token=' about', bytes=[32, 97, 98, 111, 117, 116], logprob=-4.5257497), TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-5.0257497)]),\n",
       " ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.12401338, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.12401338), TopLogprob(token=' authors', bytes=[32, 97, 117, 116, 104, 111, 114, 115], logprob=-2.3740134), TopLogprob(token=' its', bytes=[32, 105, 116, 115], logprob=-5.3740134)]),\n",
       " ChatCompletionTokenLogprob(token=' authors', bytes=[32, 97, 117, 116, 104, 111, 114, 115], logprob=-0.08970378, top_logprobs=[TopLogprob(token=' authors', bytes=[32, 97, 117, 116, 104, 111, 114, 115], logprob=-0.08970378), TopLogprob(token=' poem', bytes=[32, 112, 111, 101, 109], logprob=-3.7147038), TopLogprob(token=' origins', bytes=[32, 111, 114, 105, 103, 105, 110, 115], logprob=-3.7147038)]),\n",
       " ChatCompletionTokenLogprob(token='hip', bytes=[104, 105, 112], logprob=-1.6240566e-06, top_logprobs=[TopLogprob(token='hip', bytes=[104, 105, 112], logprob=-1.6240566e-06), TopLogprob(token='hips', bytes=[104, 105, 112, 115], logprob=-14.000002), TopLogprob(token=\"'\", bytes=[39], logprob=-15.250002)]),\n",
       " ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.43110815, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.43110815), TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-1.0561081), TopLogprob(token=',', bytes=[44], logprob=-6.181108)]),\n",
       " ChatCompletionTokenLogprob(token=' setting', bytes=[32, 115, 101, 116, 116, 105, 110, 103], logprob=-1.5046036, top_logprobs=[TopLogprob(token=' setting', bytes=[32, 115, 101, 116, 116, 105, 110, 103], logprob=-1.5046036), TopLogprob(token=' origins', bytes=[32, 111, 114, 105, 103, 105, 110, 115], logprob=-2.2546036), TopLogprob(token=' composition', bytes=[32, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110], logprob=-2.5046036)]),\n",
       " ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.00066239934, top_logprobs=[TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.00066239934), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-9.250663), TopLogprob(token=' locations', bytes=[32, 108, 111, 99, 97, 116, 105, 111, 110, 115], logprob=-9.625663)]),\n",
       " ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-1.2247427, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.34974268), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.2247427), TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-7.224743)]),\n",
       " ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-1.998142e-05, top_logprobs=[TopLogprob(token='The', bytes=[84, 104, 101], logprob=-1.998142e-05), TopLogprob(token='Od', bytes=[79, 100], logprob=-10.87502), TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-14.37502)]),\n",
       " ChatCompletionTokenLogprob(token=' Odyssey', bytes=[32, 79, 100, 121, 115, 115, 101, 121], logprob=-1.2233183e-05, top_logprobs=[TopLogprob(token=' Odyssey', bytes=[32, 79, 100, 121, 115, 115, 101, 121], logprob=-1.2233183e-05), TopLogprob(token=' Ili', bytes=[32, 73, 108, 105], logprob=-11.375012), TopLogprob(token=' Od', bytes=[32, 79, 100], logprob=-14.375012)]),\n",
       " ChatCompletionTokenLogprob(token='.\"', bytes=[46, 34], logprob=-0.22111325, top_logprobs=[TopLogprob(token='.\"', bytes=[46, 34], logprob=-0.22111325), TopLogprob(token=',\"', bytes=[44, 34], logprob=-1.8461132), TopLogprob(token='\"', bytes=[34], logprob=-3.7211132)]),\n",
       " ChatCompletionTokenLogprob(token=' He', bytes=[32, 72, 101], logprob=-2.610822, top_logprobs=[TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.9858219), TopLogprob(token=' \\n\\n', bytes=[32, 10, 10], logprob=-1.735822), TopLogprob(token=' It', bytes=[32, 73, 116], logprob=-1.735822)]),\n",
       " ChatCompletionTokenLogprob(token=' argues', bytes=[32, 97, 114, 103, 117, 101, 115], logprob=-1.0053195, top_logprobs=[TopLogprob(token=' argues', bytes=[32, 97, 114, 103, 117, 101, 115], logprob=-1.0053195), TopLogprob(token=' pos', bytes=[32, 112, 111, 115], logprob=-1.5053195), TopLogprob(token=' presents', bytes=[32, 112, 114, 101, 115, 101, 110, 116, 115], logprob=-2.2553196)]),\n",
       " ChatCompletionTokenLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-0.09894735, top_logprobs=[TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-0.09894735), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-2.7239473), TopLogprob(token=' it', bytes=[32, 105, 116], logprob=-4.4739475)]),\n",
       " ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.65493464, top_logprobs=[TopLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.65493464), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.77993464), TopLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-4.904935)]),\n",
       " ChatCompletionTokenLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-0.028754286, top_logprobs=[TopLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-0.028754286), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-4.153754), TopLogprob(token=' reflects', bytes=[32, 114, 101, 102, 108, 101, 99, 116, 115], logprob=-5.528754)]),\n",
       " ChatCompletionTokenLogprob(token=' written', bytes=[32, 119, 114, 105, 116, 116, 101, 110], logprob=-0.3781072, top_logprobs=[TopLogprob(token=' written', bytes=[32, 119, 114, 105, 116, 116, 101, 110], logprob=-0.3781072), TopLogprob(token=' composed', bytes=[32, 99, 111, 109, 112, 111, 115, 101, 100], logprob=-1.8781072), TopLogprob(token=' penned', bytes=[32, 112, 101, 110, 110, 101, 100], logprob=-2.628107)]),\n",
       " ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.9448794, top_logprobs=[TopLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.8198794), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.9448794), TopLogprob(token=' entirely', bytes=[32, 101, 110, 116, 105, 114, 101, 108, 121], logprob=-2.3198795)]),\n",
       " ChatCompletionTokenLogprob(token=' Sicily', bytes=[32, 83, 105, 99, 105, 108, 121], logprob=-0.101656616, top_logprobs=[TopLogprob(token=' Sicily', bytes=[32, 83, 105, 99, 105, 108, 121], logprob=-0.101656616), TopLogprob(token=' Trap', bytes=[32, 84, 114, 97, 112], logprob=-2.9766567), TopLogprob(token=' a', bytes=[32, 97], logprob=-3.7266567)]),\n",
       " ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.6837521, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.6837521), TopLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.8087521), TopLogprob(token=',', bytes=[44], logprob=-3.058752)]),\n",
       " ChatCompletionTokenLogprob(token=' suggests', bytes=[32, 115, 117, 103, 103, 101, 115, 116, 115], logprob=-0.97577995, top_logprobs=[TopLogprob(token=' suggests', bytes=[32, 115, 117, 103, 103, 101, 115, 116, 115], logprob=-0.97577995), TopLogprob(token=' attributes', bytes=[32, 97, 116, 116, 114, 105, 98, 117, 116, 101, 115], logprob=-2.10078), TopLogprob(token=' claims', bytes=[32, 99, 108, 97, 105, 109, 115], logprob=-2.35078)]),\n",
       " ChatCompletionTokenLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-0.6023142, top_logprobs=[TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-0.6023142), TopLogprob(token=' it', bytes=[32, 105, 116], logprob=-1.1023142), TopLogprob(token=' a', bytes=[32, 97], logprob=-3.1023142)]),\n",
       " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.81109816, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.81109816), TopLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.93609816), TopLogprob(token=' its', bytes=[32, 105, 116, 115], logprob=-2.436098)]),\n",
       " ChatCompletionTokenLogprob(token=' young', bytes=[32, 121, 111, 117, 110, 103], logprob=-0.030971946, top_logprobs=[TopLogprob(token=' young', bytes=[32, 121, 111, 117, 110, 103], logprob=-0.030971946), TopLogprob(token=' woman', bytes=[32, 119, 111, 109, 97, 110], logprob=-3.655972), TopLogprob(token=' very', bytes=[32, 118, 101, 114, 121], logprob=-6.030972)]),\n",
       " ChatCompletionTokenLogprob(token=' woman', bytes=[32, 119, 111, 109, 97, 110], logprob=-0.0023375894, top_logprobs=[TopLogprob(token=' woman', bytes=[32, 119, 111, 109, 97, 110], logprob=-0.0023375894), TopLogprob(token=' female', bytes=[32, 102, 101, 109, 97, 108, 101], logprob=-6.1273375), TopLogprob(token=' Sic', bytes=[32, 83, 105, 99], logprob=-9.502337)]),\n",
       " ChatCompletionTokenLogprob(token=' named', bytes=[32, 110, 97, 109, 101, 100], logprob=-0.7297672, top_logprobs=[TopLogprob(token=' named', bytes=[32, 110, 97, 109, 101, 100], logprob=-0.7297672), TopLogprob(token=' authored', bytes=[32, 97, 117, 116, 104, 111, 114, 101, 100], logprob=-1.3547672), TopLogprob(token=',', bytes=[44], logprob=-2.8547673)]),\n",
       " ChatCompletionTokenLogprob(token=' Na', bytes=[32, 78, 97], logprob=-9.014684e-06, top_logprobs=[TopLogprob(token=' Na', bytes=[32, 78, 97], logprob=-9.014684e-06), TopLogprob(token=' \"', bytes=[32, 34], logprob=-13.125009), TopLogprob(token='Na', bytes=[78, 97], logprob=-13.250009)]),\n",
       " ChatCompletionTokenLogprob(token='us', bytes=[117, 115], logprob=-5.080963e-06, top_logprobs=[TopLogprob(token='us', bytes=[117, 115], logprob=-5.080963e-06), TopLogprob(token='usika', bytes=[117, 115, 105, 107, 97], logprob=-12.250005), TopLogprob(token='usic', bytes=[117, 115, 105, 99], logprob=-15.500005)]),\n",
       " ChatCompletionTokenLogprob(token='ica', bytes=[105, 99, 97], logprob=-1.504853e-06, top_logprobs=[TopLogprob(token='ica', bytes=[105, 99, 97], logprob=-1.504853e-06), TopLogprob(token='ikaa', bytes=[105, 107, 97, 97], logprob=-14.250002), TopLogprob(token='ikka', bytes=[105, 107, 107, 97], logprob=-15.250002)]),\n",
       " ChatCompletionTokenLogprob(token='a', bytes=[97], logprob=-2.3392786e-06, top_logprobs=[TopLogprob(token='a', bytes=[97], logprob=-2.3392786e-06), TopLogprob(token='ä', bytes=[195, 164], logprob=-14.000002), TopLogprob(token='aa', bytes=[97, 97], logprob=-14.375002)]),\n",
       " ChatCompletionTokenLogprob(token=' authored', bytes=[32, 97, 117, 116, 104, 111, 114, 101, 100], logprob=-0.681608, top_logprobs=[TopLogprob(token=' authored', bytes=[32, 97, 117, 116, 104, 111, 114, 101, 100], logprob=-0.681608), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-1.681608), TopLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-2.056608)]),\n",
       " ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.04865345, top_logprobs=[TopLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.04865345), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-3.0486534), TopLogprob(token=' parts', bytes=[32, 112, 97, 114, 116, 115], logprob=-10.673654)]),\n",
       " ChatCompletionTokenLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-0.24811216, top_logprobs=[TopLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-0.24811216), TopLogprob(token='.', bytes=[46], logprob=-1.6231122), TopLogprob(token=',', bytes=[44], logprob=-3.8731122)]),\n",
       " ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.291463, top_logprobs=[TopLogprob(token='The', bytes=[84, 104, 101], logprob=-0.291463), TopLogprob(token='\"The', bytes=[34, 84, 104, 101], logprob=-2.541463), TopLogprob(token='In', bytes=[73, 110], logprob=-2.666463)]),\n",
       " ChatCompletionTokenLogprob(token=' narrative', bytes=[32, 110, 97, 114, 114, 97, 116, 105, 118, 101], logprob=-0.8512492, top_logprobs=[TopLogprob(token=' narrative', bytes=[32, 110, 97, 114, 114, 97, 116, 105, 118, 101], logprob=-0.8512492), TopLogprob(token=' story', bytes=[32, 115, 116, 111, 114, 121], logprob=-1.7262492), TopLogprob(token=' poem', bytes=[32, 112, 111, 101, 109], logprob=-1.9762492)]),\n",
       " ChatCompletionTokenLogprob(token=' follows', bytes=[32, 102, 111, 108, 108, 111, 119, 115], logprob=-0.5963923, top_logprobs=[TopLogprob(token=' follows', bytes=[32, 102, 111, 108, 108, 111, 119, 115], logprob=-0.5963923), TopLogprob(token=' unfolds', bytes=[32, 117, 110, 102, 111, 108, 100, 115], logprob=-1.8463923), TopLogprob(token=' recount', bytes=[32, 114, 101, 99, 111, 117, 110, 116], logprob=-3.0963922)]),\n",
       " ChatCompletionTokenLogprob(token=' U', bytes=[32, 85], logprob=-1.0709814, top_logprobs=[TopLogprob(token=' Od', bytes=[32, 79, 100], logprob=-0.9459814), TopLogprob(token=' U', bytes=[32, 85], logprob=-1.0709814), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.3209814)]),\n",
       " ChatCompletionTokenLogprob(token='ly', bytes=[108, 121], logprob=-1.2664457e-06, top_logprobs=[TopLogprob(token='ly', bytes=[108, 121], logprob=-1.2664457e-06), TopLogprob(token='lys', bytes=[108, 121, 115], logprob=-13.625001), TopLogprob(token='LY', bytes=[76, 89], logprob=-17.875002)]),\n",
       " ChatCompletionTokenLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-1.9361265e-07), TopLogprob(token='ss', bytes=[115, 115], logprob=-15.875), TopLogprob(token='ssis', bytes=[115, 115, 105, 115], logprob=-18.75)]),\n",
       " ChatCompletionTokenLogprob(token=' (', bytes=[32, 40], logprob=-0.11649246, top_logprobs=[TopLogprob(token=' (', bytes=[32, 40], logprob=-0.11649246), TopLogprob(token=\"'\", bytes=[39], logprob=-3.1164925), TopLogprob(token=',', bytes=[44], logprob=-3.3664925)]),\n",
       " ChatCompletionTokenLogprob(token='Od', bytes=[79, 100], logprob=-0.011917895, top_logprobs=[TopLogprob(token='Od', bytes=[79, 100], logprob=-0.011917895), TopLogprob(token='or', bytes=[111, 114], logprob=-4.886918), TopLogprob(token='also', bytes=[97, 108, 115, 111], logprob=-5.511918)]),\n",
       " ChatCompletionTokenLogprob(token='ys', bytes=[121, 115], logprob=-0.0002036596, top_logprobs=[TopLogprob(token='ys', bytes=[121, 115], logprob=-0.0002036596), TopLogprob(token='yssey', bytes=[121, 115, 115, 101, 121], logprob=-8.500204), TopLogprob(token='YS', bytes=[89, 83], logprob=-15.750204)]),\n",
       " ChatCompletionTokenLogprob(token='se', bytes=[115, 101], logprob=-7.89631e-07, top_logprobs=[TopLogprob(token='se', bytes=[115, 101], logprob=-7.89631e-07), TopLogprob(token='sea', bytes=[115, 101, 97], logprob=-14.750001), TopLogprob(token='-se', bytes=[45, 115, 101], logprob=-15.500001)]),\n",
       " ChatCompletionTokenLogprob(token='us', bytes=[117, 115], logprob=-3.1281633e-07, top_logprobs=[TopLogprob(token='us', bytes=[117, 115], logprob=-3.1281633e-07), TopLogprob(token='ys', bytes=[121, 115], logprob=-15.5), TopLogprob(token='US', bytes=[85, 83], logprob=-18.25)]),\n",
       " ChatCompletionTokenLogprob(token=')', bytes=[41], logprob=-0.033663906, top_logprobs=[TopLogprob(token=')', bytes=[41], logprob=-0.033663906), TopLogprob(token='),', bytes=[41, 44], logprob=-3.408664), TopLogprob(token=\")'\", bytes=[41, 39], logprob=-11.408664)]),\n",
       " ChatCompletionTokenLogprob(token=' as', bytes=[32, 97, 115], logprob=-0.33087745, top_logprobs=[TopLogprob(token=' as', bytes=[32, 97, 115], logprob=-0.33087745), TopLogprob(token=' on', bytes=[32, 111, 110], logprob=-1.9558774), TopLogprob(token=' after', bytes=[32, 97, 102, 116, 101, 114], logprob=-2.2058775)]),\n",
       " ChatCompletionTokenLogprob(token=' he', bytes=[32, 104, 101], logprob=-1.6524515e-05, top_logprobs=[TopLogprob(token=' he', bytes=[32, 104, 101], logprob=-1.6524515e-05), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-11.625016), TopLogprob(token=\" he's\", bytes=[32, 104, 101, 39, 115], logprob=-12.875016)]),\n",
       " ChatCompletionTokenLogprob(token=' struggles', bytes=[32, 115, 116, 114, 117, 103, 103, 108, 101, 115], logprob=-0.49108312, top_logprobs=[TopLogprob(token=' struggles', bytes=[32, 115, 116, 114, 117, 103, 103, 108, 101, 115], logprob=-0.49108312), TopLogprob(token=' attempts', bytes=[32, 97, 116, 116, 101, 109, 112, 116, 115], logprob=-1.9910831), TopLogprob(token=' faces', bytes=[32, 102, 97, 99, 101, 115], logprob=-2.7410831)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.00049024174, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.00049024174), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-9.00049), TopLogprob(token=' against', bytes=[32, 97, 103, 97, 105, 110, 115, 116], logprob=-9.00049)]),\n",
       " ChatCompletionTokenLogprob(token=' return', bytes=[32, 114, 101, 116, 117, 114, 110], logprob=-4.572941e-05, top_logprobs=[TopLogprob(token=' return', bytes=[32, 114, 101, 116, 117, 114, 110], logprob=-4.572941e-05), TopLogprob(token=' find', bytes=[32, 102, 105, 110, 100], logprob=-10.625046), TopLogprob(token=' reun', bytes=[32, 114, 101, 117, 110], logprob=-11.875046)]),\n",
       " ChatCompletionTokenLogprob(token=' home', bytes=[32, 104, 111, 109, 101], logprob=-0.02977919, top_logprobs=[TopLogprob(token=' home', bytes=[32, 104, 111, 109, 101], logprob=-0.02977919), TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-3.5297792), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-10.529779)]),\n",
       " ChatCompletionTokenLogprob(token=' after', bytes=[32, 97, 102, 116, 101, 114], logprob=-0.9154878, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.5404878), TopLogprob(token=' after', bytes=[32, 97, 102, 116, 101, 114], logprob=-0.9154878), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-4.165488)]),\n",
       " ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0028794145, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0028794145), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-7.0028796), TopLogprob(token=' fighting', bytes=[32, 102, 105, 103, 104, 116, 105, 110, 103], logprob=-7.2528796)]),\n",
       " ChatCompletionTokenLogprob(token=' Trojan', bytes=[32, 84, 114, 111, 106, 97, 110], logprob=-0.04340768, top_logprobs=[TopLogprob(token=' Trojan', bytes=[32, 84, 114, 111, 106, 97, 110], logprob=-0.04340768), TopLogprob(token=' fall', bytes=[32, 102, 97, 108, 108], logprob=-3.1684077), TopLogprob(token=' war', bytes=[32, 119, 97, 114], logprob=-9.043407)]),\n",
       " ChatCompletionTokenLogprob(token=' War', bytes=[32, 87, 97, 114], logprob=-4.429897e-05, top_logprobs=[TopLogprob(token=' War', bytes=[32, 87, 97, 114], logprob=-4.429897e-05), TopLogprob(token=' war', bytes=[32, 119, 97, 114], logprob=-10.500044), TopLogprob(token=' Wars', bytes=[32, 87, 97, 114, 115], logprob=-11.000044)]),\n",
       " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.45218304, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.45218304), TopLogprob(token=',', bytes=[44], logprob=-1.077183), TopLogprob(token=' while', bytes=[32, 119, 104, 105, 108, 101], logprob=-3.827183)]),\n",
       " ChatCompletionTokenLogprob(token=' Despite', bytes=[32, 68, 101, 115, 112, 105, 116, 101], logprob=-2.380407, top_logprobs=[TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.88040704), TopLogprob(token=' Despite', bytes=[32, 68, 101, 115, 112, 105, 116, 101], logprob=-2.380407), TopLogprob(token=' He', bytes=[32, 72, 101], logprob=-2.380407)]),\n",
       " ChatCompletionTokenLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.8237892, top_logprobs=[TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.8237892), TopLogprob(token=' being', bytes=[32, 98, 101, 105, 110, 103], logprob=-1.8237891), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-2.6987891)]),\n",
       " ChatCompletionTokenLogprob(token=' long', bytes=[32, 108, 111, 110, 103], logprob=-3.154883, top_logprobs=[TopLogprob(token=' longing', bytes=[32, 108, 111, 110, 103, 105, 110, 103], logprob=-1.404883), TopLogprob(token=' clever', bytes=[32, 99, 108, 101, 118, 101, 114], logprob=-1.654883), TopLogprob(token=' bravery', bytes=[32, 98, 114, 97, 118, 101, 114, 121], logprob=-2.404883)]),\n",
       " ChatCompletionTokenLogprob(token='ings', bytes=[105, 110, 103, 115], logprob=-0.6485059, top_logprobs=[TopLogprob(token='ings', bytes=[105, 110, 103, 115], logprob=-0.6485059), TopLogprob(token=' journey', bytes=[32, 106, 111, 117, 114, 110, 101, 121], logprob=-1.2735059), TopLogprob(token=' absence', bytes=[32, 97, 98, 115, 101, 110, 99, 101], logprob=-2.773506)]),\n",
       " ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.21041644, top_logprobs=[TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.21041644), TopLogprob(token=',', bytes=[44], logprob=-1.9604164), TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-3.7104163)]),\n",
       " ChatCompletionTokenLogprob(token=' Ith', bytes=[32, 73, 116, 104], logprob=-0.27733505, top_logprobs=[TopLogprob(token=' Ith', bytes=[32, 73, 116, 104], logprob=-0.27733505), TopLogprob(token=' home', bytes=[32, 104, 111, 109, 101], logprob=-1.902335), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-2.4023352)]),\n",
       " ChatCompletionTokenLogprob(token='aca', bytes=[97, 99, 97], logprob=-6.869018e-06, top_logprobs=[TopLogprob(token='aca', bytes=[97, 99, 97], logprob=-6.869018e-06), TopLogprob(token='aka', bytes=[97, 107, 97], logprob=-12.250007), TopLogprob(token='ica', bytes=[105, 99, 97], logprob=-13.125007)]),\n",
       " ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.22598916, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.22598916), TopLogprob(token=',', bytes=[44], logprob=-1.6009891), TopLogprob(token='—', bytes=[226, 128, 148], logprob=-8.100989)]),\n",
       " ChatCompletionTokenLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.16495186, top_logprobs=[TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.16495186), TopLogprob(token=' Pen', bytes=[32, 80, 101, 110], logprob=-2.0399518), TopLogprob(token=' family', bytes=[32, 102, 97, 109, 105, 108, 121], logprob=-5.039952)]),\n",
       " ChatCompletionTokenLogprob(token=' wife', bytes=[32, 119, 105, 102, 101], logprob=-0.031965245, top_logprobs=[TopLogprob(token=' wife', bytes=[32, 119, 105, 102, 101], logprob=-0.031965245), TopLogprob(token=' family', bytes=[32, 102, 97, 109, 105, 108, 121], logprob=-3.5319653), TopLogprob(token=' faithful', bytes=[32, 102, 97, 105, 116, 104, 102, 117, 108], logprob=-6.9069653)]),\n",
       " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-1.223573, top_logprobs=[TopLogprob(token=' Pen', bytes=[32, 80, 101, 110], logprob=-0.3485729), TopLogprob(token=',', bytes=[44], logprob=-1.223573), TopLogprob(token=' Penny', bytes=[32, 80, 101, 110, 110, 121], logprob=-10.098573)]),\n",
       " ChatCompletionTokenLogprob(token=' Pen', bytes=[32, 80, 101, 110], logprob=-3.5597102e-05, top_logprobs=[TopLogprob(token=' Pen', bytes=[32, 80, 101, 110], logprob=-3.5597102e-05), TopLogprob(token=' he', bytes=[32, 104, 101], logprob=-10.625035), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-13.125035)]),\n",
       " ChatCompletionTokenLogprob(token='elope', bytes=[101, 108, 111, 112, 101], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='elope', bytes=[101, 108, 111, 112, 101], logprob=-1.9361265e-07), TopLogprob(token='el', bytes=[101, 108], logprob=-16.375), TopLogprob(token='é', bytes=[195, 169], logprob=-18.5)]),\n",
       " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0005666146, top_logprobs=[TopLogprob(token=',', bytes=[44], logprob=-0.0005666146), TopLogprob(token='—', bytes=[226, 128, 148], logprob=-7.6255665), TopLogprob(token='—a', bytes=[226, 128, 148, 97], logprob=-10.6255665)]),\n",
       " ChatCompletionTokenLogprob(token=' he', bytes=[32, 104, 101], logprob=-0.14612311, top_logprobs=[TopLogprob(token=' he', bytes=[32, 104, 101], logprob=-0.14612311), TopLogprob(token=' U', bytes=[32, 85], logprob=-2.0211232), TopLogprob(token=\" he's\", bytes=[32, 104, 101, 39, 115], logprob=-6.271123)]),\n",
       " ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.3616399, top_logprobs=[TopLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.3616399), TopLogprob(token=' faces', bytes=[32, 102, 97, 99, 101, 115], logprob=-1.3616399), TopLogprob(token=' finds', bytes=[32, 102, 105, 110, 100, 115], logprob=-3.86164)]),\n",
       " ChatCompletionTokenLogprob(token=' held', bytes=[32, 104, 101, 108, 100], logprob=-0.89379066, top_logprobs=[TopLogprob(token=' held', bytes=[32, 104, 101, 108, 100], logprob=-0.89379066), TopLogprob(token=' detained', bytes=[32, 100, 101, 116, 97, 105, 110, 101, 100], logprob=-1.2687907), TopLogprob(token=' trapped', bytes=[32, 116, 114, 97, 112, 112, 101, 100], logprob=-1.5187907)]),\n",
       " ChatCompletionTokenLogprob(token=' captive', bytes=[32, 99, 97, 112, 116, 105, 118, 101], logprob=-0.0011520056, top_logprobs=[TopLogprob(token=' captive', bytes=[32, 99, 97, 112, 116, 105, 118, 101], logprob=-0.0011520056), TopLogprob(token=' by', bytes=[32, 98, 121], logprob=-7.751152), TopLogprob(token=' back', bytes=[32, 98, 97, 99, 107], logprob=-8.001152)]),\n",
       " ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.023730937, top_logprobs=[TopLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.023730937), TopLogprob(token=' on', bytes=[32, 111, 110], logprob=-3.773731), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-7.6487308)]),\n",
       " ChatCompletionTokenLogprob(token=' Cal', bytes=[32, 67, 97, 108], logprob=-0.8986051, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.5236051), TopLogprob(token=' Cal', bytes=[32, 67, 97, 108], logprob=-0.8986051), TopLogprob(token=' Kal', bytes=[32, 75, 97, 108], logprob=-8.523605)]),\n",
       " ChatCompletionTokenLogprob(token='yp', bytes=[121, 112], logprob=-1.3856493e-06, top_logprobs=[TopLogprob(token='yp', bytes=[121, 112], logprob=-1.3856493e-06), TopLogprob(token='y', bytes=[121], logprob=-13.625001), TopLogprob(token='py', bytes=[112, 121], logprob=-16.375002)]),\n",
       " ChatCompletionTokenLogprob(token='so', bytes=[115, 111], logprob=0.0, top_logprobs=[TopLogprob(token='so', bytes=[115, 111], logprob=0.0), TopLogprob(token=' so', bytes=[32, 115, 111], logprob=-18.125), TopLogprob(token='o', bytes=[111], logprob=-20.625)]),\n",
       " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-1.8680208, top_logprobs=[TopLogprob(token=' on', bytes=[32, 111, 110], logprob=-0.24302077), TopLogprob(token=',', bytes=[44], logprob=-1.8680208), TopLogprob(token='.', bytes=[46], logprob=-2.9930208)]),\n",
       " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.26229015, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.26229015), TopLogprob(token=' who', bytes=[32, 119, 104, 111], logprob=-1.5122901), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-5.38729)]),\n",
       " ChatCompletionTokenLogprob(token=' n', bytes=[32, 110], logprob=-0.081236556, top_logprobs=[TopLogprob(token=' n', bytes=[32, 110], logprob=-0.081236556), TopLogprob(token=' goddess', bytes=[32, 103, 111, 100, 100, 101, 115, 115], logprob=-2.7062366), TopLogprob(token=' beautiful', bytes=[32, 98, 101, 97, 117, 116, 105, 102, 117, 108], logprob=-5.2062364)]),\n",
       " ChatCompletionTokenLogprob(token='ymph', bytes=[121, 109, 112, 104], logprob=-1.2664457e-06, top_logprobs=[TopLogprob(token='ymph', bytes=[121, 109, 112, 104], logprob=-1.2664457e-06), TopLogprob(token='ym', bytes=[121, 109], logprob=-13.625001), TopLogprob(token=' n', bytes=[32, 110], logprob=-18.125002)]),\n",
       " ChatCompletionTokenLogprob(token=' who', bytes=[32, 119, 104, 111], logprob=-0.067812964, top_logprobs=[TopLogprob(token=' who', bytes=[32, 119, 104, 111], logprob=-0.067812964), TopLogprob(token='.', bytes=[46], logprob=-3.567813), TopLogprob(token=' enam', bytes=[32, 101, 110, 97, 109], logprob=-3.942813)]),\n",
       " ChatCompletionTokenLogprob(token=' wishes', bytes=[32, 119, 105, 115, 104, 101, 115], logprob=-1.3086498, top_logprobs=[TopLogprob(token=' desires', bytes=[32, 100, 101, 115, 105, 114, 101, 115], logprob=-0.43364972), TopLogprob(token=' wishes', bytes=[32, 119, 105, 115, 104, 101, 115], logprob=-1.3086498), TopLogprob(token=' loves', bytes=[32, 108, 111, 118, 101, 115], logprob=-3.0586498)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.025672838, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.025672838), TopLogprob(token=' him', bytes=[32, 104, 105, 109], logprob=-3.900673), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-5.275673)]),\n",
       " ChatCompletionTokenLogprob(token=' make', bytes=[32, 109, 97, 107, 101], logprob=-1.4485788, top_logprobs=[TopLogprob(token=' marry', bytes=[32, 109, 97, 114, 114, 121], logprob=-0.4485789), TopLogprob(token=' make', bytes=[32, 109, 97, 107, 101], logprob=-1.4485788), TopLogprob(token=' keep', bytes=[32, 107, 101, 101, 112], logprob=-2.0735788)]),\n",
       " ChatCompletionTokenLogprob(token=' him', bytes=[32, 104, 105, 109], logprob=-7.612634e-05, top_logprobs=[TopLogprob(token=' him', bytes=[32, 104, 105, 109], logprob=-7.612634e-05), TopLogprob(token=' U', bytes=[32, 85], logprob=-9.500076), TopLogprob(token=' them', bytes=[32, 116, 104, 101, 109], logprob=-14.375076)]),\n",
       " ChatCompletionTokenLogprob(token=' her', bytes=[32, 104, 101, 114], logprob=-0.8262345, top_logprobs=[TopLogprob(token=' immortal', bytes=[32, 105, 109, 109, 111, 114, 116, 97, 108], logprob=-0.5762345), TopLogprob(token=' her', bytes=[32, 104, 101, 114], logprob=-0.8262345), TopLogprob(token=' hers', bytes=[32, 104, 101, 114, 115], logprob=-8.951235)]),\n",
       " ChatCompletionTokenLogprob(token=' immortal', bytes=[32, 105, 109, 109, 111, 114, 116, 97, 108], logprob=-0.6144246, top_logprobs=[TopLogprob(token=' immortal', bytes=[32, 105, 109, 109, 111, 114, 116, 97, 108], logprob=-0.6144246), TopLogprob(token=' husband', bytes=[32, 104, 117, 115, 98, 97, 110, 100], logprob=-0.8644246), TopLogprob(token=' eternal', bytes=[32, 101, 116, 101, 114, 110, 97, 108], logprob=-3.3644247)]),\n",
       " ChatCompletionTokenLogprob(token=' husband', bytes=[32, 104, 117, 115, 98, 97, 110, 100], logprob=-0.1606788, top_logprobs=[TopLogprob(token=' husband', bytes=[32, 104, 117, 115, 98, 97, 110, 100], logprob=-0.1606788), TopLogprob(token=' partner', bytes=[32, 112, 97, 114, 116, 110, 101, 114], logprob=-2.7856789), TopLogprob(token=' cons', bytes=[32, 99, 111, 110, 115], logprob=-3.0356789)]),\n",
       " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0019590827, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.0019590827), TopLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-6.251959), TopLogprob(token=' while', bytes=[32, 119, 104, 105, 108, 101], logprob=-11.001959)]),\n",
       " ChatCompletionTokenLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.48454976, top_logprobs=[TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.48454976), TopLogprob(token=' Meanwhile', bytes=[32, 77, 101, 97, 110, 119, 104, 105, 108, 101], logprob=-1.3595498), TopLogprob(token=' As', bytes=[32, 65, 115], logprob=-3.1095498)]),\n",
       " ChatCompletionTokenLogprob(token=' gods', bytes=[32, 103, 111, 100, 115], logprob=-0.18891385, top_logprobs=[TopLogprob(token=' gods', bytes=[32, 103, 111, 100, 115], logprob=-0.18891385), TopLogprob(token=' story', bytes=[32, 115, 116, 111, 114, 121], logprob=-2.1889138), TopLogprob(token=' poem', bytes=[32, 112, 111, 101, 109], logprob=-4.063914)]),\n",
       " ChatCompletionTokenLogprob(token=' conven', bytes=[32, 99, 111, 110, 118, 101, 110], logprob=-0.46529195, top_logprobs=[TopLogprob(token=' conven', bytes=[32, 99, 111, 110, 118, 101, 110], logprob=-0.46529195), TopLogprob(token=' eventually', bytes=[32, 101, 118, 101, 110, 116, 117, 97, 108, 108, 121], logprob=-2.215292), TopLogprob(token=' discuss', bytes=[32, 100, 105, 115, 99, 117, 115, 115], logprob=-2.965292)]),\n",
       " ChatCompletionTokenLogprob(token='e', bytes=[101], logprob=-9.388769e-05, top_logprobs=[TopLogprob(token='e', bytes=[101], logprob=-9.388769e-05), TopLogprob(token='ed', bytes=[101, 100], logprob=-9.625093), TopLogprob(token='ing', bytes=[105, 110, 103], logprob=-10.500093)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.71318394, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.71318394), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-1.4631839), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-1.9631839)]),\n",
       " ChatCompletionTokenLogprob(token=' discuss', bytes=[32, 100, 105, 115, 99, 117, 115, 115], logprob=-0.04624257, top_logprobs=[TopLogprob(token=' discuss', bytes=[32, 100, 105, 115, 99, 117, 115, 115], logprob=-0.04624257), TopLogprob(token=' decide', bytes=[32, 100, 101, 99, 105, 100, 101], logprob=-3.6712425), TopLogprob(token=' address', bytes=[32, 97, 100, 100, 114, 101, 115, 115], logprob=-4.2962427)]),\n",
       " ChatCompletionTokenLogprob(token=' U', bytes=[32, 85], logprob=-0.043841098, top_logprobs=[TopLogprob(token=' U', bytes=[32, 85], logprob=-0.043841098), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-3.1688411), TopLogprob(token=' Od', bytes=[32, 79, 100], logprob=-8.293841)]),\n",
       " ChatCompletionTokenLogprob(token='ly', bytes=[108, 121], logprob=-2.9352968e-06, top_logprobs=[TopLogprob(token='ly', bytes=[108, 121], logprob=-2.9352968e-06), TopLogprob(token='lys', bytes=[108, 121, 115], logprob=-12.750003), TopLogprob(token='dy', bytes=[100, 121], logprob=-19.000004)]),\n",
       " ChatCompletionTokenLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-3.1281633e-07, top_logprobs=[TopLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-3.1281633e-07), TopLogprob(token='ss', bytes=[115, 115], logprob=-15.375), TopLogprob(token='ssis', bytes=[115, 115, 105, 115], logprob=-18.25)]),\n",
       " ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-0.23128761, top_logprobs=[TopLogprob(token=\"'\", bytes=[39], logprob=-0.23128761), TopLogprob(token='’', bytes=[226, 128, 153], logprob=-1.7312876), TopLogprob(token=\"'s\", bytes=[39, 115], logprob=-3.8562877)]),\n",
       " ChatCompletionTokenLogprob(token=' fate', bytes=[32, 102, 97, 116, 101], logprob=-0.39933074, top_logprobs=[TopLogprob(token=' fate', bytes=[32, 102, 97, 116, 101], logprob=-0.39933074), TopLogprob(token=' plight', bytes=[32, 112, 108, 105, 103, 104, 116], logprob=-1.1493307), TopLogprob(token=' suffering', bytes=[32, 115, 117, 102, 102, 101, 114, 105, 110, 103], logprob=-5.6493306)]),\n",
       " ChatCompletionTokenLogprob(token=';', bytes=[59], logprob=-0.31467173, top_logprobs=[TopLogprob(token=';', bytes=[59], logprob=-0.31467173), TopLogprob(token=',', bytes=[44], logprob=-1.5646718), TopLogprob(token='.', bytes=[46], logprob=-3.9396718)]),\n",
       " ChatCompletionTokenLogprob(token=' Min', bytes=[32, 77, 105, 110], logprob=-0.44142827, top_logprobs=[TopLogprob(token=' Min', bytes=[32, 77, 105, 110], logprob=-0.44142827), TopLogprob(token=' ultimately', bytes=[32, 117, 108, 116, 105, 109, 97, 116, 101, 108, 121], logprob=-2.1914282), TopLogprob(token=' Athena', bytes=[32, 65, 116, 104, 101, 110, 97], logprob=-2.4414282)]),\n",
       " ChatCompletionTokenLogprob(token='erva', bytes=[101, 114, 118, 97], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='erva', bytes=[101, 114, 118, 97], logprob=-1.9361265e-07), TopLogprob(token='erv', bytes=[101, 114, 118], logprob=-16.375), TopLogprob(token='vera', bytes=[118, 101, 114, 97], logprob=-17.375)]),\n",
       " ChatCompletionTokenLogprob(token=' advocates', bytes=[32, 97, 100, 118, 111, 99, 97, 116, 101, 115], logprob=-0.94436526, top_logprobs=[TopLogprob(token=' advocates', bytes=[32, 97, 100, 118, 111, 99, 97, 116, 101, 115], logprob=-0.94436526), TopLogprob(token=' (', bytes=[32, 40], logprob=-1.3193653), TopLogprob(token=' ple', bytes=[32, 112, 108, 101], logprob=-1.8193653)]),\n",
       " ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.0052669575, top_logprobs=[TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.0052669575), TopLogprob(token=' on', bytes=[32, 111, 110], logprob=-5.255267), TopLogprob(token=' strongly', bytes=[32, 115, 116, 114, 111, 110, 103, 108, 121], logprob=-11.005267)]),\n",
       " ChatCompletionTokenLogprob(token=' him', bytes=[32, 104, 105, 109], logprob=-0.23037796, top_logprobs=[TopLogprob(token=' him', bytes=[32, 104, 105, 109], logprob=-0.23037796), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-1.6053779), TopLogprob(token=' U', bytes=[32, 85], logprob=-5.480378)]),\n",
       " ChatCompletionTokenLogprob(token=' while', bytes=[32, 119, 104, 105, 108, 101], logprob=-0.58515596, top_logprobs=[TopLogprob(token=' while', bytes=[32, 119, 104, 105, 108, 101], logprob=-0.58515596), TopLogprob(token=',', bytes=[44], logprob=-1.085156), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-3.460156)]),\n",
       " ChatCompletionTokenLogprob(token=' Pose', bytes=[32, 80, 111, 115, 101], logprob=-0.27589205, top_logprobs=[TopLogprob(token=' Pose', bytes=[32, 80, 111, 115, 101], logprob=-0.27589205), TopLogprob(token=' Neptune', bytes=[32, 78, 101, 112, 116, 117, 110, 101], logprob=-1.650892), TopLogprob(token=' J', bytes=[32, 74], logprob=-3.650892)]),\n",
       " ChatCompletionTokenLogprob(token='idon', bytes=[105, 100, 111, 110], logprob=-0.00038217165, top_logprobs=[TopLogprob(token='idon', bytes=[105, 100, 111, 110], logprob=-0.00038217165), TopLogprob(token='id', bytes=[105, 100], logprob=-7.875382), TopLogprob(token='iden', bytes=[105, 100, 101, 110], logprob=-13.875382)]),\n",
       " ChatCompletionTokenLogprob(token=' remains', bytes=[32, 114, 101, 109, 97, 105, 110, 115], logprob=-0.80334157, top_logprobs=[TopLogprob(token=' remains', bytes=[32, 114, 101, 109, 97, 105, 110, 115], logprob=-0.80334157), TopLogprob(token=' continues', bytes=[32, 99, 111, 110, 116, 105, 110, 117, 101, 115], logprob=-0.80334157), TopLogprob(token=' opp', bytes=[32, 111, 112, 112], logprob=-3.3033416)]),\n",
       " ChatCompletionTokenLogprob(token=' v', bytes=[32, 118], logprob=-0.79528546, top_logprobs=[TopLogprob(token=' v', bytes=[32, 118], logprob=-0.79528546), TopLogprob(token=' hostile', bytes=[32, 104, 111, 115, 116, 105, 108, 101], logprob=-1.4202855), TopLogprob(token=' antagon', bytes=[32, 97, 110, 116, 97, 103, 111, 110], logprob=-2.4202855)]),\n",
       " ChatCompletionTokenLogprob(token='enge', bytes=[101, 110, 103, 101], logprob=0.0, top_logprobs=[TopLogprob(token='enge', bytes=[101, 110, 103, 101], logprob=0.0), TopLogprob(token='ext', bytes=[101, 120, 116], logprob=-21.5), TopLogprob(token='agrant', bytes=[97, 103, 114, 97, 110, 116], logprob=-21.625)]),\n",
       " ChatCompletionTokenLogprob(token='ful', bytes=[102, 117, 108], logprob=-0.00039051592, top_logprobs=[TopLogprob(token='ful', bytes=[102, 117, 108], logprob=-0.00039051592), TopLogprob(token='fully', bytes=[102, 117, 108, 108, 121], logprob=-7.8753905), TopLogprob(token='ant', bytes=[97, 110, 116], logprob=-11.50039)]),\n",
       " ChatCompletionTokenLogprob(token=' due', bytes=[32, 100, 117, 101], logprob=-0.66235334, top_logprobs=[TopLogprob(token=' due', bytes=[32, 100, 117, 101], logprob=-0.66235334), TopLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-2.0373533), TopLogprob(token='.', bytes=[46], logprob=-2.2873533)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-1.9816675e-06, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-1.9816675e-06), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-15.062502), TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-15.125002)]),\n",
       " ChatCompletionTokenLogprob(token=' U', bytes=[32, 85], logprob=-0.38398346, top_logprobs=[TopLogprob(token=' U', bytes=[32, 85], logprob=-0.38398346), TopLogprob(token=' past', bytes=[32, 112, 97, 115, 116], logprob=-1.5089835), TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-3.1339834)]),\n",
       " ChatCompletionTokenLogprob(token='ly', bytes=[108, 121], logprob=-1.3067608e-05, top_logprobs=[TopLogprob(token='ly', bytes=[108, 121], logprob=-1.3067608e-05), TopLogprob(token='lys', bytes=[108, 121, 115], logprob=-11.250013), TopLogprob(token='LY', bytes=[76, 89], logprob=-18.125013)]),\n",
       " ChatCompletionTokenLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-3.1281633e-07, top_logprobs=[TopLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-3.1281633e-07), TopLogprob(token='ss', bytes=[115, 115], logprob=-15.125), TopLogprob(token='ssis', bytes=[115, 115, 105, 115], logprob=-17.75)]),\n",
       " ChatCompletionTokenLogprob(token=' bl', bytes=[32, 98, 108], logprob=-0.40079865, top_logprobs=[TopLogprob(token=' bl', bytes=[32, 98, 108], logprob=-0.40079865), TopLogprob(token=\"'\", bytes=[39], logprob=-1.4007987), TopLogprob(token='’', bytes=[226, 128, 153], logprob=-2.6507986)]),\n",
       " ChatCompletionTokenLogprob(token='inding', bytes=[105, 110, 100, 105, 110, 103], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='inding', bytes=[105, 110, 100, 105, 110, 103], logprob=-1.9361265e-07), TopLogprob(token='ighting', bytes=[105, 103, 104, 116, 105, 110, 103], logprob=-16.125), TopLogprob(token='iding', bytes=[105, 100, 105, 110, 103], logprob=-17.125)]),\n",
       " ChatCompletionTokenLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.1929045, top_logprobs=[TopLogprob(token=' his', bytes=[32, 104, 105, 115], logprob=-0.1929045), TopLogprob(token=' Pol', bytes=[32, 80, 111, 108], logprob=-2.0679045), TopLogprob(token=' Pose', bytes=[32, 80, 111, 115, 101], logprob=-4.0679045)]),\n",
       " ChatCompletionTokenLogprob(token=' son', bytes=[32, 115, 111, 110], logprob=-0.0023424695, top_logprobs=[TopLogprob(token=' son', bytes=[32, 115, 111, 110], logprob=-0.0023424695), TopLogprob(token=' Cycl', bytes=[32, 67, 121, 99, 108], logprob=-6.3773427), TopLogprob(token=' cycl', bytes=[32, 99, 121, 99, 108], logprob=-7.3773427)]),\n",
       " ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.45126784, top_logprobs=[TopLogprob(token=',', bytes=[44], logprob=-0.45126784), TopLogprob(token=' Pol', bytes=[32, 80, 111, 108], logprob=-1.0762678), TopLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-4.4512677)]),\n",
       " ChatCompletionTokenLogprob(token=' Pol', bytes=[32, 80, 111, 108], logprob=-0.0478366, top_logprobs=[TopLogprob(token=' Pol', bytes=[32, 80, 111, 108], logprob=-0.0478366), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-3.1728365), TopLogprob(token=' Cycl', bytes=[32, 67, 121, 99, 108], logprob=-5.422837)]),\n",
       " ChatCompletionTokenLogprob(token='yp', bytes=[121, 112], logprob=-1.2664457e-06, top_logprobs=[TopLogprob(token='yp', bytes=[121, 112], logprob=-1.2664457e-06), TopLogprob(token='ym', bytes=[121, 109], logprob=-14.125001), TopLogprob(token='yc', bytes=[121, 99], logprob=-16.000002)]),\n",
       " ChatCompletionTokenLogprob(token='hem', bytes=[104, 101, 109], logprob=-5.5122365e-07, top_logprobs=[TopLogprob(token='hem', bytes=[104, 101, 109], logprob=-5.5122365e-07), TopLogprob(token='heme', bytes=[104, 101, 109, 101], logprob=-14.625001), TopLogprob(token='he', bytes=[104, 101], logprob=-18.625)]),\n",
       " ChatCompletionTokenLogprob(token='us', bytes=[117, 115], logprob=-0.00015514737, top_logprobs=[TopLogprob(token='us', bytes=[117, 115], logprob=-0.00015514737), TopLogprob(token='os', bytes=[111, 115], logprob=-8.875155), TopLogprob(token='ous', bytes=[111, 117, 115], logprob=-11.125155)]),\n",
       " ChatCompletionTokenLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-0.08832604, top_logprobs=[TopLogprob(token='.\\n\\n', bytes=[46, 10, 10], logprob=-0.08832604), TopLogprob(token='.', bytes=[46], logprob=-2.588326), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-4.713326)]),\n",
       " ChatCompletionTokenLogprob(token='U', bytes=[85], logprob=-1.7697521, top_logprobs=[TopLogprob(token='Tele', bytes=[84, 101, 108, 101], logprob=-1.1447521), TopLogprob(token='As', bytes=[65, 115], logprob=-1.5197521), TopLogprob(token='U', bytes=[85], logprob=-1.7697521)]),\n",
       " ChatCompletionTokenLogprob(token='ly', bytes=[108, 121], logprob=-4.6206227e-05, top_logprobs=[TopLogprob(token='ly', bytes=[108, 121], logprob=-4.6206227e-05), TopLogprob(token='lys', bytes=[108, 121, 115], logprob=-10.000046), TopLogprob(token='ph', bytes=[112, 104], logprob=-16.125046)]),\n",
       " ChatCompletionTokenLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-5.5122365e-07, top_logprobs=[TopLogprob(token='sses', bytes=[115, 115, 101, 115], logprob=-5.5122365e-07), TopLogprob(token='ss', bytes=[115, 115], logprob=-14.625001), TopLogprob(token='ssis', bytes=[115, 115, 105, 115], logprob=-16.75)]),\n",
       " ChatCompletionTokenLogprob(token=' eventually', bytes=[32, 101, 118, 101, 110, 116, 117, 97, 108, 108, 121], logprob=-0.39478797, top_logprobs=[TopLogprob(token=' eventually', bytes=[32, 101, 118, 101, 110, 116, 117, 97, 108, 108, 121], logprob=-0.39478797), TopLogprob(token=' ultimately', bytes=[32, 117, 108, 116, 105, 109, 97, 116, 101, 108, 121], logprob=-2.269788), TopLogprob(token=\"'\", bytes=[39], logprob=-2.644788)]),\n",
       " ChatCompletionTokenLogprob(token=' receives', bytes=[32, 114, 101, 99, 101, 105, 118, 101, 115], logprob=-0.18747087, top_logprobs=[TopLogprob(token=' receives', bytes=[32, 114, 101, 99, 101, 105, 118, 101, 115], logprob=-0.18747087), TopLogprob(token=' emb', bytes=[32, 101, 109, 98], logprob=-3.312471), TopLogprob(token=' escapes', bytes=[32, 101, 115, 99, 97, 112, 101, 115], logprob=-3.437471)]),\n",
       " ChatCompletionTokenLogprob(token=' permission', bytes=[32, 112, 101, 114, 109, 105, 115, 115, 105, 111, 110], logprob=-0.5700055, top_logprobs=[TopLogprob(token=' permission', bytes=[32, 112, 101, 114, 109, 105, 115, 115, 105, 111, 110], logprob=-0.5700055), TopLogprob(token=' divine', bytes=[32, 100, 105, 118, 105, 110, 101], logprob=-1.9450054), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-2.3200054)]),\n",
       " ChatCompletionTokenLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-0.06199435, top_logprobs=[TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-0.06199435), TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-2.8119943), TopLogprob(token=' through', bytes=[32, 116, 104, 114, 111, 117, 103, 104], logprob=-11.811995)]),\n",
       " ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.3592261, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.3592261), TopLogprob(token=' Zeus', bytes=[32, 90, 101, 117, 115], logprob=-1.9842261), TopLogprob(token=' Jupiter', bytes=[32, 74, 117, 112, 105, 116, 101, 114], logprob=-2.4842262)]),\n",
       " ChatCompletionTokenLogprob(token=' gods', bytes=[32, 103, 111, 100, 115], logprob=-0.010409662, top_logprobs=[TopLogprob(token=' gods', bytes=[32, 103, 111, 100, 115], logprob=-0.010409662), TopLogprob(token=' other', bytes=[32, 111, 116, 104, 101, 114], logprob=-5.01041), TopLogprob(token=' de', bytes=[32, 100, 101], logprob=-6.26041)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.004181683, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.004181683), TopLogprob(token=',', bytes=[44], logprob=-6.754182), TopLogprob(token=' (', bytes=[32, 40], logprob=-7.254182)]),\n",
       " ChatCompletionTokenLogprob(token=' leave', bytes=[32, 108, 101, 97, 118, 101], logprob=-0.05432942, top_logprobs=[TopLogprob(token=' leave', bytes=[32, 108, 101, 97, 118, 101], logprob=-0.05432942), TopLogprob(token=' return', bytes=[32, 114, 101, 116, 117, 114, 110], logprob=-3.5543294), TopLogprob(token=' depart', bytes=[32, 100, 101, 112, 97, 114, 116], logprob=-4.1793294)]),\n",
       " ChatCompletionTokenLogprob(token=' Cal', bytes=[32, 67, 97, 108], logprob=-0.005266719, top_logprobs=[TopLogprob(token=' Cal', bytes=[32, 67, 97, 108], logprob=-0.005266719), TopLogprob(token='.', bytes=[46], logprob=-6.0052667), TopLogprob(token=',', bytes=[44], logprob=-6.8802667)]),\n",
       " ChatCompletionTokenLogprob(token='yp', bytes=[121, 112], logprob=-1.8624639e-06, top_logprobs=[TopLogprob(token='yp', bytes=[121, 112], logprob=-1.8624639e-06), TopLogprob(token='y', bytes=[121], logprob=-13.375002), TopLogprob(token='py', bytes=[112, 121], logprob=-15.250002)]),\n",
       " ChatCompletionTokenLogprob(token='so', bytes=[115, 111], logprob=0.0, top_logprobs=[TopLogprob(token='so', bytes=[115, 111], logprob=0.0), TopLogprob(token=' so', bytes=[32, 115, 111], logprob=-17.375), TopLogprob(token='-so', bytes=[45, 115, 111], logprob=-19.875)]),\n",
       " ChatCompletionTokenLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.5038124, top_logprobs=[TopLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.5038124), TopLogprob(token='’s', bytes=[226, 128, 153, 115], logprob=-1.5038123), TopLogprob(token='.', bytes=[46], logprob=-2.1288123)]),\n",
       " ChatCompletionTokenLogprob(token=' island', bytes=[32, 105, 115, 108, 97, 110, 100], logprob=-0.0024634062, top_logprobs=[TopLogprob(token=' island', bytes=[32, 105, 115, 108, 97, 110, 100], logprob=-0.0024634062), TopLogprob(token=' isle', bytes=[32, 105, 115, 108, 101], logprob=-6.1274633), TopLogprob(token=' Island', bytes=[32, 73, 115, 108, 97, 110, 100], logprob=-9.252463)]),\n",
       " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.38888106, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.38888106), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-2.263881), TopLogprob(token=' after', bytes=[32, 97, 102, 116, 101, 114], logprob=-2.638881)]),\n",
       " ChatCompletionTokenLogprob(token=' He', bytes=[32, 72, 101], logprob=-1.2804205, top_logprobs=[TopLogprob(token=' He', bytes=[32, 72, 101], logprob=-1.2804205), TopLogprob(token=' With', bytes=[32, 87, 105, 116, 104], logprob=-1.2804205), TopLogprob(token=' After', bytes=[32, 65, 102, 116, 101, 114], logprob=-1.9054205)]),\n",
       " ChatCompletionTokenLogprob(token=' builds', bytes=[32, 98, 117, 105, 108, 100, 115], logprob=-0.655376, top_logprobs=[TopLogprob(token=' builds', bytes=[32, 98, 117, 105, 108, 100, 115], logprob=-0.655376), TopLogprob(token=' constructs', bytes=[32, 99, 111, 110, 115, 116, 114, 117, 99, 116, 115], logprob=-0.780376), TopLogprob(token=' faces', bytes=[32, 102, 97, 99, 101, 115], logprob=-4.780376)]),\n",
       " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.0005045389, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.0005045389), TopLogprob(token=' himself', bytes=[32, 104, 105, 109, 115, 101, 108, 102], logprob=-7.6255045), TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-11.8755045)]),\n",
       " ChatCompletionTokenLogprob(token=' raft', bytes=[32, 114, 97, 102, 116], logprob=-0.0005928284, top_logprobs=[TopLogprob(token=' raft', bytes=[32, 114, 97, 102, 116], logprob=-0.0005928284), TopLogprob(token=' makes', bytes=[32, 109, 97, 107, 101, 115], logprob=-7.6255927), TopLogprob(token=' sturdy', bytes=[32, 115, 116, 117, 114, 100, 121], logprob=-9.750593)]),\n",
       " ChatCompletionTokenLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-1.4407197, top_logprobs=[TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.8157197), TopLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-1.4407197), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-1.4407197)]),\n",
       " ChatCompletionTokenLogprob(token=' her', bytes=[32, 104, 101, 114], logprob=-0.1011926, top_logprobs=[TopLogprob(token=' her', bytes=[32, 104, 101, 114], logprob=-0.1011926), TopLogprob(token=' Cal', bytes=[32, 67, 97, 108], logprob=-2.6011927), TopLogprob(token=' divine', bytes=[32, 100, 105, 118, 105, 110, 101], logprob=-5.1011925)]),\n",
       " ChatCompletionTokenLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-0.6128916, top_logprobs=[TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-0.6128916), TopLogprob(token=' assistance', bytes=[32, 97, 115, 115, 105, 115, 116, 97, 110, 99, 101], logprob=-0.8628916), TopLogprob(token=' aid', bytes=[32, 97, 105, 100], logprob=-3.4878917)]),\n",
       " ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.13572887, top_logprobs=[TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.13572887), TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-2.1357288), TopLogprob(token=',', bytes=[44], logprob=-5.010729)]),\n",
       " ChatCompletionTokenLogprob(token=' faces', bytes=[32, 102, 97, 99, 101, 115], logprob=-0.06802692, top_logprobs=[TopLogprob(token=' faces', bytes=[32, 102, 97, 99, 101, 115], logprob=-0.06802692), TopLogprob(token=' encounters', bytes=[32, 101, 110, 99, 111, 117, 110, 116, 101, 114, 115], logprob=-2.943027), TopLogprob(token=' soon', bytes=[32, 115, 111, 111, 110], logprob=-4.943027)])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1.logprobs.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text provided is an eBook version of \"The Odyssey,\" attributed to Homer and translated by Samuel Butler. The tale recounts the adventures of Odysseus, a Greek hero attempting to return home after the Trojan War. The eBook, available through Project Gutenberg without restrictions in many parts of the world, delves into themes such as perseverance, loyalty, and the roles of fate and divine intervention.\n",
       "\n",
       "**Key Elements:**\n",
       "\n",
       "- **Content Structure:** The eBook includes a preface detailing Butler's translation process, providing context about his previous works regarding \"The Odyssey.\" It then presents the epic poem divided into twenty-four books.\n",
       "\n",
       "- **Plot Overview:** \n",
       "  - In Book I, gods discuss Odysseus's plight as he is trapped on Calypso's island while his son Telemachus faces trouble from suitors in Ithaca.\n",
       "  - Following divine discussions about aiding Odysseus' return home from Calypso’s grasp.\n",
       "  - Various vessels containing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer2.message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Project Gutenberg eBook of \"The Odyssey,\" translated by Samuel Butler, is a free and accessible version of Homer's epic poem. It recounts the adventures of Odysseus (Ulysses) as he struggles to return home to Ithaca after the Trojan War, facing numerous obstacles including divine interventions and mythical creatures. The text includes a comprehensive structure with multiple books detailing Odysseus's trials, his interactions with gods like Athena and Poseidon, and his eventual reunion with his family. The translator offers insights into the poem's origins, themes, and narrative style while presenting it in prose for easier understanding. This edition is part of Project Gutenberg's mission to make literary works freely available to the public."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert at summarizing text. You are a master of the English language and can summarize any given text in a concise and informative way. You have summarized the worlds longest book in just one paragraph and now you are going to summarize the text below.\"},\n",
    "    {\"role\": \"user\", \"content\": text},\n",
    "]\n",
    "\n",
    "answer3 = get_completion_from_messages(messages, temperature=0.75, max_tokens=500, frequency_penalty=0.7, logprobs=False,)\n",
    "display(Markdown(answer3.message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)\n",
    "\n",
    "> - `echo` is an outdated parameter and is not available in the current version of the API.\n",
    "> - `logit_bias` controls the bias of the output towards certain tokens. It can be used to improve the quality of the translation. If the logit bias is too high, it will simply write the same word over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "def get_completion_from_messages(messages, temperature=0, max_tokens=100, frequency_penalty=0, logit_bias=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens to generate\n",
    "        frequency_penalty=frequency_penalty, # this is the penalty for using words that are already in the text\n",
    "        logit_bias=logit_bias, # this is the logit bias for the next token\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '''\n",
    "I was uploading informative posts about Puerto Ricoand got some comments. Someone asked me if there were pirates in Puerto Rico. I found this article about Pirata Cofresi and i want you to summarize it and translated\n",
    "to english. Feel free to use common expressions and idioms in english, since i would like to sound like a native speaker.\n",
    "The text you will translate will be given below in spanish. Translate it to English\n",
    "\n",
    "Roberto Kupferschein Ramírez de Arellano, mejor conocido como “Roberto Cofresí” o “El Pirata Cofresí”\n",
    "Nació el 17 de junio de 1791 en Cabo Rojo. Parte de una de las familias criollas más importantes en la Isla.\n",
    "\n",
    "Le decían \"Cofresí\" porque a los puertorriqueños se les hacía muy difícil pronunciar su apellido \"Kupferschein\". Hijo de Franz von Kupferschein, aristócrata millonario de Austria y de la caborrojeña María Germana Ramírez de Arellano. Desde joven se destacó como marinero y dominaba el mar. En un principio fue un reconocido Corsario (no un pirata) que defendía a España de sus enemigos.\n",
    "\n",
    "Sus aventuras en alta mar fueron parte del contrabando característico del siglo XVIII en las costas de Puerto Rico. Con el pasar de los años Cofresí se convierte en un \"Pirata\" cuando, influenciado por Simón Bolívar, decide unirse a la liberación de las Américas. Ahí comienza a atacar tanto a barcos españoles, como estadounidenses.\n",
    "\n",
    "Roberto Cofresí fue encarcelado luego de un sangriento enfrentamiento en el Mar Caribe, con barcos españoles y estadounidenses, que habían hecho una alianza para atraparlo.\n",
    "\n",
    "Hundieron su famoso barco “Ana\". Anteriormente había perdido su otro barco “El Mosquito”. Se le acusaba por haber cometido fechorías, robos y asesinatos en alta mar y en las costas de Puerto Rico. Esto culminó en el fusilamiento de Roberto Cofresí y diez de sus hombres en el Castillo San Felipe del Morro, el 29 de marzo de 1825. Alejandro Tapia escribió la primera obra literaria dedicada a Cofresí. Cofresí era muy querido por los puertorriqueños, conocido como el “Robin Hood” boricua.\n",
    "'''\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in different world cultures and languages. You can easily and accurately translate text from one language to another and always can capture idioms and expresions so that the translation is not only accurate but also culturally relevant.\"},\n",
    "    {\"role\": \"user\", \"content\": text2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = get_completion_from_messages(messages, max_tokens = 250)\n",
    "translation_logit = get_completion_from_messages(messages, max_tokens=250, logit_bias={9680: 100, 41524: 100})\n",
    "# translation_logit = get_completion_from_messages(messages, logit_bias={token_id: 100})\n",
    "translation_logit2 = get_completion_from_messages(messages, max_tokens=250, logit_bias={9680: 4})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberto Kupferschein Ramírez de Arellano, better known as \"Roberto Cofresí\" or \"El Pirata Cofresí,\" was born on June 17, 1791, in Cabo Rojo. He came from one of the most prominent Creole families on the island.\n",
      "\n",
      "He was nicknamed \"Cofresí\" because Puerto Ricans found it difficult to pronounce his last name, \"Kupferschein.\" He was the son of Franz von Kupferschein, a wealthy Austrian aristocrat, and María Germana Ramírez de Arellano from Cabo Rojo. From a young age, he stood out as a sailor and was well-versed in the ways of the sea. Initially, he was a recognized corsair (not a pirate) who defended Spain from its enemies.\n",
      "\n",
      "His adventures at sea were part of the characteristic smuggling activities of the 18th century along the coasts of Puerto Rico. Over the years, Cofresí became a \"pirate\" when, influenced by Simón Bolívar, he decided to join the liberation movements in the Americas. This marked the beginning of his attacks on both Spanish and American ships.\n",
      "\n",
      "Roberto Cofresí was imprisoned after a bloody\n",
      "**************\n",
      "CaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbeanCaribbean\n",
      "******************\n",
      "Roberto Kupferschein Ramírez de Arellano, better known as \"Roberto Cofresí\" or \"El Pirata Cofresí,\" was born on June 17, 1791, in Cabo Rojo. He came from one of the most prominent Creole families on the island.\n",
      "\n",
      "He was nicknamed \"Cofresí\" because Puerto Ricans found it difficult to pronounce his last name, \"Kupferschein.\" He was the son of Franz von Kupferschein, a wealthy Austrian aristocrat, and María Germana Ramírez de Arellano from Cabo Rojo. From a young age, he stood out as a sailor and was well-versed in the ways of the sea. Initially, he was a recognized corsair (not a pirate) who defended Spain against its enemies.\n",
      "\n",
      "His adventures at sea were part of the characteristic smuggling activities of the 18th century along the coasts of Puerto Rico. Over the years, Cofresí became a \"pirate\" when, influenced by Simón Bolívar, he decided to join the liberation movements in the Americas. This marked the beginning of his attacks on both Spanish and American ships.\n",
      "\n",
      "Roberto Cofresí was imprisoned after a bloody\n"
     ]
    }
   ],
   "source": [
    "print(translation.message.content)\n",
    "print(\"**************\")\n",
    "print(translation_logit.message.content)\n",
    "print(\"******************\")\n",
    "print(translation_logit2.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberto Kupferschein Ramírez de Arellano, better known as \"Roberto Cofresí\" or \"El Pirata Cofresí,\" was born on June 17, 1791, in Cabo Rojo. He came from one of the most prominent Creole families on the island.\n",
      "\n",
      "He was nicknamed \"Cofresí\" because Puerto Ricans found it difficult to pronounce his last name, \"Kupferschein.\" He was the son of Franz von Kupferschein, a wealthy Austrian aristocrat, and María Germana Ramírez de Arellano from Cabo Rojo. From a young age, he excelled as a sailor and was well-versed in the ways of the sea. Initially, he was a renowned corsair (not a pirate) who defended Spain from its enemies.\n",
      "\n",
      "His adventures at sea were part of the characteristic smuggling that took place along the coasts of Puerto Rico in the 18th century. Over the years, Cofresí became a \"pirate\" when, influenced by Simón Bolívar, he decided to join the liberation movements in the Americas. This marked the beginning of his attacks on both Spanish and American ships.\n",
      "\n",
      "Roberto Cofresí was imprisoned after\n"
     ]
    }
   ],
   "source": [
    "translation_logit3 = get_completion_from_messages(messages, temperature=0.4, max_tokens=250, logit_bias={9680: 4})\n",
    "print(translation_logit3.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analisys\n",
    "model = \"gpt-4o-mini\"\n",
    "def get_completion_from_messages(messages, temperature=0, max_tokens=100, frequency_penalty=0, n=1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens to generate\n",
    "        frequency_penalty=frequency_penalty, # this is the penalty for using words that are already in the text\n",
    "        n=n\n",
    "        )\n",
    "    return response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I hate this movie. It was so boring and the acting was terrible.\"\n",
    "def msg(text):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in sentiment analysis. You can easily and accurately determine the sentiment of any given text and can provide a detailed analysis of the sentiment of the text. You only tell people if the sentiments are positive, negative, or neutral, and no more than that.\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = get_completion_from_messages(msg(text))\n",
    "s1 = get_completion_from_messages(msg(text), temperature=0.5, max_tokens=10, frequency_penalty=0.7, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is negative.\n",
      "The sentiment of the text is negative.\n",
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The sentiment of the text is negative.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "print(s0.message.content)\n",
    "print(s1.message.content)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Positive\n",
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Positive', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "text = \"I love this movie. It was so exciting and the acting was amazing.\"\n",
    "\n",
    "s0 = get_completion_from_messages(msg(text))\n",
    "s1 = get_completion_from_messages(msg(text), temperature=0.5, max_tokens=10, frequency_penalty=0.7, n=3)\n",
    "print(s0.message.content)\n",
    "print(s1.message.content)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n",
      "Neutral\n",
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Neutral', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "text = \"I am hungry\"\n",
    "\n",
    "s0 = get_completion_from_messages(msg(text))\n",
    "s1 = get_completion_from_messages(msg(text), temperature=0.5, max_tokens=10, frequency_penalty=0.7, n=3)\n",
    "print(s0.message.content)\n",
    "print(s1.message.content)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "def get_completion_from_messages(messages, temperature=0, max_tokens=100, frequency_penalty=0, stop=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens to generate\n",
    "        frequency_penalty=frequency_penalty, # this is the penalty for using words that are already in the text\n",
    "        # presence_penalty=presence_penalty, # this is the penalty for using words that are already in the text\n",
    "        stop=stop\n",
    "        )\n",
    "    return response.choices[0]\n",
    "def msg(text):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a mind reader and can predict what the user is going to say next. You can easily and accurately predict the next words and stop when you think so.\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...feel a bit restless. I think I need to get up and stretch or maybe take a short walk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"I've been seated here all day and I'm starting to...\"\n",
    "s0 = get_completion_from_messages(msg(text))\n",
    "s1 = get_completion_from_messages(msg(text), temperature=0.5, max_tokens=10, frequency_penalty=0.7, stop=[\".\"])\n",
    "print(s0.message.content)\n",
    "print(s1.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maybe you should grab a snack or think about what to have for lunch. What are you in the mood for?\n",
      "Maybe it's time to grab a snack or think about\n"
     ]
    }
   ],
   "source": [
    "text = \"I've been seated here all day and I'm starting to get hungry.\"\n",
    "s0 = get_completion_from_messages(msg(text))\n",
    "s1 = get_completion_from_messages(msg(text), temperature=0.5, max_tokens=10, frequency_penalty=0.7, stop=[\"\\n\", \"eat\"])\n",
    "print(s0.message.content)\n",
    "print(s1.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
